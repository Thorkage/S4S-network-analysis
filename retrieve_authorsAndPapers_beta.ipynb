{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from pybliometrics.scopus import AuthorRetrieval\n",
    "from pybliometrics.scopus import AbstractRetrieval\n",
    "from pybliometrics.scopus import PlumXMetrics\n",
    "\n",
    "from dicttoxml import dicttoxml\n",
    "from xml.dom.minidom import parseString\n",
    "\n",
    "#initialize geolocator to go from city, country to lat,lon\n",
    "from geopy.geocoders import Nominatim\n",
    "# Initialize Nominatim API\n",
    "geolocator = Nominatim(user_agent=\"MyApp\")\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "import pyalex\n",
    "pyalex.config.email = \"\" \n",
    "\n",
    "def flatten_chain(matrix):\n",
    "     return list(chain.from_iterable(matrix))\n",
    "\n",
    "\n",
    "client_orcid = open('orcid_config.json')\n",
    "client_orcid = json.load(client_orcid)\n",
    "\n",
    "client_scopus = open('scopus_config.json')\n",
    "client_scopus = json.load(client_scopus)\n",
    "\n",
    "df_names = pd.read_csv('people_in_S4S_pureFiltered_withAuthorIDs.csv',keep_default_na=False,index_col=[0])\n",
    "# df_persons.reset_index(inplace=True)\n",
    "# df_persons.drop('Index',axis=1,inplace=True)\n",
    "# df_persons.index.names = ['Index']\n",
    "\n",
    "#orcid start up\n",
    "client_id = client_orcid['client_id']\n",
    "client_secret = client_orcid['client_secret']\n",
    "\n",
    "resp = requests.post(url=\"https://orcid.org/oauth/token\",\n",
    "                     headers={'Accept':'application/json'},\n",
    "                     data={'client_id':client_id, 'client_secret':client_secret,'grant_type': 'client_credentials', 'scope':'/read-public'}\n",
    "                     )\n",
    "access_token = resp.json()['access_token']\n",
    "\n",
    "\n",
    "df_subjectAreas = pd.read_xml('scopus_subject_classification.xml')\n",
    "df_subjectAreas.set_index('code',inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [47:01<00:00, 13.90s/it] \n"
     ]
    }
   ],
   "source": [
    "#scopus & openAlex data retrieval\n",
    "with open('saved_locations.json') as fd:\n",
    "     saved_locations = json.load(fd)\n",
    "\n",
    "for i in tqdm(df_names.index):\n",
    "    subjectAreas_dict = {}\n",
    "\n",
    "    first_name = df_names['firstname'][i]\n",
    "    last_name = df_names['lastname'][i]\n",
    "    scopusId = df_names['scopusID'][i]\n",
    "    # openalexId = df_names['openalexID'][i]\n",
    "\n",
    "    if scopusId != '':\n",
    "\n",
    "        resp = requests.get(url=f\"https://api.elsevier.com/content/author/author_id/{scopusId}/\", headers={'X-ELS-APIKey':client_scopus['apikey'], 'X-ELS-Insttoken':client_scopus['insttoken'], 'accept':'application/json','view':'ENHANCED'})\n",
    "\n",
    "        author_dict = {}\n",
    "        coAuthor_dict = {}       \n",
    "\n",
    "        author_dict['S4Sid'] = i\n",
    "        author_dict['firstname'] = df_names['firstname'][i]\n",
    "        author_dict['lastname'] = df_names['lastname'][i]\n",
    "        author_dict['scopusID'] = df_names['scopusID'][i]\n",
    "        author_dict['orcID'] = df_names['orcID'][i]\n",
    "        # author_dict['openalexID'] = df_names['openalexID'][i]\n",
    "\n",
    "\n",
    "        #affiliation and location \n",
    "\n",
    "\n",
    "        #multiple current affiliations...\n",
    "        if isinstance(resp.json()['author-retrieval-response'][0]['author-profile']['affiliation-current']['affiliation'],list) == True:\n",
    "            author_dict['current_affiliation_institute'] = resp.json()['author-retrieval-response'][0]['author-profile']['affiliation-current']['affiliation'][0]['ip-doc']['afdispname']\n",
    "            author_dict['current_affiliation_country'] = resp.json()['author-retrieval-response'][0]['author-profile']['affiliation-current']['affiliation'][0]['ip-doc']['address']['country']\n",
    "            author_dict['current_affiliation_city'] = resp.json()['author-retrieval-response'][0]['author-profile']['affiliation-current']['affiliation'][0]['ip-doc']['address']['city']\n",
    "        else:\n",
    "            try:\n",
    "                author_dict['current_affiliation_institute'] = resp.json()['author-retrieval-response'][0]['author-profile']['affiliation-current']['affiliation']['ip-doc']['afdispname']\n",
    "                author_dict['current_affiliation_country'] = resp.json()['author-retrieval-response'][0]['author-profile']['affiliation-current']['affiliation']['ip-doc']['address']['country']\n",
    "                author_dict['current_affiliation_city'] = resp.json()['author-retrieval-response'][0]['author-profile']['affiliation-current']['affiliation']['ip-doc']['address']['city']\n",
    "            except:\n",
    "\n",
    "                author_dict['current_affiliation_institute'] = resp.json()['author-retrieval-response'][0]['author-profile']['affiliation-history']['affiliation'][0]['ip-doc']['afdispname']\n",
    "                author_dict['current_affiliation_country'] = resp.json()['author-retrieval-response'][0]['author-profile']['affiliation-history']['affiliation'][0]['ip-doc']['address']['country']\n",
    "                author_dict['current_affiliation_city'] = resp.json()['author-retrieval-response'][0]['author-profile']['affiliation-history']['affiliation'][0]['ip-doc']['address']['city']\n",
    "        \n",
    "        location_abb = f'{author_dict['current_affiliation_city']}, {author_dict['current_affiliation_country']}'\n",
    "        \n",
    "        if location_abb in saved_locations.keys():\n",
    "            location = saved_locations[location_abb]\n",
    "            author_dict['current_affiliation_lat'] = location['lat']\n",
    "            author_dict['current_affiliation_lon'] = location['lon']\n",
    "\n",
    "        else:\n",
    "            location = geolocator.geocode(query = {'country':scopus_record.affiliation_history[0]._asdict()['country'], 'city':scopus_record.affiliation_history[0]._asdict()['city']})\n",
    "\n",
    "            if location != None:\n",
    "                author_dict['current_affiliation_lat'] = location.latitude\n",
    "                author_dict['current_affiliation_lon'] = location.longitude\n",
    "                saved_locations[location_abb] = {}\n",
    "                saved_locations[location_abb]['lat'] = location.latitude\n",
    "                saved_locations[location_abb]['lon'] = location.longitude\n",
    "            else:\n",
    "                author_dict['current_affiliation_lat'] = ''\n",
    "                author_dict['current_affiliation_lon'] = ''\n",
    "                saved_locations[location_abb] = {}\n",
    "                saved_locations[location_abb]['lat'] = ''\n",
    "                saved_locations[location_abb]['lon'] = ''\n",
    "\n",
    "        author_dict['publicationRange'] = tuple([resp.json()['author-retrieval-response'][0]['author-profile']['publication-range']['@end'],resp.json()['author-retrieval-response'][0]['author-profile']['publication-range']['@start']])\n",
    "        # author_dict['researchAreas'] = [item._asdict()['area'] for item in scopus_record.subject_areas] if scopus_record.subject_areas != None else ''\n",
    "        author_dict['citationCount'] = resp.json()['author-retrieval-response'][0]['coredata']['citation-count']\n",
    "        author_dict['citedByCount'] = resp.json()['author-retrieval-response'][0]['coredata']['cited-by-count']\n",
    "        author_dict['documentCount'] = resp.json()['author-retrieval-response'][0]['coredata']['document-count']\n",
    "\n",
    "\n",
    "        resp = requests.get(url=f\"https://api.elsevier.com/content/search/scopus\", headers={'X-ELS-APIKey':client_scopus['apikey'], 'X-ELS-Insttoken':client_scopus['insttoken'], 'accept':'application/json','view':'enhanced'},\n",
    "                            params={'query':f'AU-ID({scopusId}) AND PUBYEAR > 2019', 'cursor':'*'})\n",
    "        author_docs =  resp.json()['search-results']['entry']\n",
    "\n",
    "        num_results = int(resp.json()['search-results']['opensearch:totalResults'])\n",
    "        for page in np.arange(25,num_results,25):\n",
    "            resp = requests.get(url=f\"https://api.elsevier.com/content/search/scopus\", headers={'X-ELS-APIKey':client_scopus['apikey'], 'X-ELS-Insttoken':client_scopus['insttoken'], 'accept':'application/json','view':'enhanced'},\n",
    "                                    params={'query':f'AU-ID({scopusId}) AND PUBYEAR > 2019', 'start':str(page)})\n",
    "            for entry in resp.json()['search-results']['entry']:\n",
    "                author_docs.append(entry)\n",
    "\n",
    "        author_dict['publishedArticles'] = [item['eid'] for item in author_docs] if 'error' not in resp.json()['search-results']['entry'][0].keys() else ''\n",
    "\n",
    "\n",
    "        if 'error' not in resp.json()['search-results']['entry'][0].keys():\n",
    "            for item in author_docs:\n",
    "                # scopus_paper = item._asdict()\n",
    "                paper_dict = {}\n",
    "                paper_dict['eid'] = item['eid']\n",
    "                paper_dict['doi'] = item['prism:doi'] if 'prism:doi' in item.keys() else ''\n",
    "\n",
    "                url = item['prism:url']\n",
    "                resp = requests.get(url=url, headers={'X-ELS-APIKey':client_scopus['apikey'], 'X-ELS-Insttoken':client_scopus['insttoken'], 'accept':'application/json','view':'enhanced'})\n",
    "                # if paper_dict['doi'] = ''\n",
    "\n",
    "                \n",
    "                paper_dict['title'] = resp.json()['abstracts-retrieval-response']['item']['bibrecord']['head']['citation-title']\n",
    "\n",
    "                paper_dict['authorCount'] = len(resp.json()['abstracts-retrieval-response']['authors']['author'])\n",
    "\n",
    "\n",
    "\n",
    "                date = ''\n",
    "                try:\n",
    "                    date+=resp.json()['abstracts-retrieval-response']['item']['bibrecord']['head']['source']['publicationdate']['day']\n",
    "                    date+='.'\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    date+=resp.json()['abstracts-retrieval-response']['item']['bibrecord']['head']['source']['publicationdate']['month']\n",
    "                    date+='.'\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    date+=resp.json()['abstracts-retrieval-response']['item']['bibrecord']['head']['source']['publicationdate']['year']\n",
    "                    date+='.'\n",
    "                except:\n",
    "                    pass\n",
    "                paper_dict['releaseDate'] = date \n",
    "                paper_dict['citationCount'] = resp.json()['abstracts-retrieval-response']['coredata']['citedby-count']\n",
    "                \n",
    "                paper_dict['authorNames'] = [str(author['preferred-name']['ce:given-name']) + ' ' + str(author['preferred-name']['ce:surname']) for author in resp.json()['abstracts-retrieval-response']['authors']['author']]\n",
    "                paper_dict['authorScopusIds'] =  [author['@auid'] for author in resp.json()['abstracts-retrieval-response']['authors']['author']]\n",
    "                \n",
    "                for id in (paper_dict['authorScopusIds']):\n",
    "                    if id in coAuthor_dict:\n",
    "                        coAuthor_dict[id] += 1\n",
    "                    else:\n",
    "                        coAuthor_dict[id] = 1\n",
    "                \n",
    "                try:\n",
    "                    paper_dict['type'] = resp.json()['abstracts-retrieval-response']['coredata']['subtypeDescription']\n",
    "                    # paper_dict['refCount'] = abstract.refcount if abstract.refcount != None else ''\n",
    "\n",
    "\n",
    "                    paper_dict['authorKeywords'] = [keyw['$'] for keyw in resp.json()['abstracts-retrieval-response']['authkeywords']['author-keyword']]\n",
    "                    paper_dict['idxterms'] = [keyw['$'] for keyw in resp.json()['abstracts-retrieval-response']['idxterms']['mainterm']]\n",
    "\n",
    "\n",
    "\n",
    "                    paper_dict['abstract'] = resp.json()['abstracts-retrieval-response']['coredata']['dc:description']\n",
    "\n",
    "                    paper_dict['subjectAreas'] = [item['@code'] for item in resp.json()['abstracts-retrieval-response']['subject-areas']['subject-area']]\n",
    "                    for code in paper_dict['subjectAreas']:\n",
    "                        if code in subjectAreas_dict:\n",
    "                            subjectAreas_dict[code] += 1\n",
    "                        else:\n",
    "                            subjectAreas_dict[code] = 1\n",
    "\n",
    "\n",
    "                    # paper_dict['references'] = []\n",
    "                    # for ref in (abstract.references):\n",
    "                    #     ref = ref._asdict()\n",
    "                    #     eid = \"2-s2.0-\" + ref['id']\n",
    "                    #     doi = ref['doi'] if ref['doi']!=None else \"\"\n",
    "                    #     authorNames = ref['authors'].split(\";\")if ref['authors']!= None else ''\n",
    "                    #     authorIds = ref['authors_auid'].split(\";\") if ref['authors_auid']!= None else ''\n",
    "                    #     releaseDate = ref['coverDate']\n",
    "                    #     citationCount = ref['citedbycount']\n",
    "                    #     paper_dict['references'].append({'eid':eid,\n",
    "                    #                                     'doi':doi,\n",
    "                    #                                     'authorNames':authorNames,\n",
    "                    #                                     'authorIds':authorIds,\n",
    "                    #                                     'releaseDate':releaseDate,\n",
    "                    #                                     'citationCount':citationCount})\n",
    "                except:\n",
    "                        pass\n",
    "                \n",
    "                #PLUMX metrics\n",
    "                # try:\n",
    "                #     plum = PlumXMetrics(paper_dict['doi'],id_type='doi')\n",
    "                    \n",
    "                #     for i in range(len(plum.citation)):\n",
    "                #          name = plum.citation[i]._asdict()['name']\n",
    "                #          paper_dict['plumX_'+name] = plum.citation[i]._asdict()['total']\n",
    "\n",
    "                #     for i in range(len(plum.social_media)):\n",
    "                #          name = plum.social_media[i]._asdict()['name']\n",
    "                #          paper_dict['plumX_'+name] = plum.social_media[i]._asdict()['total']\n",
    "\n",
    "                #     for i in range(len(plum.mention)):\n",
    "                #          name = plum.mention[i]._asdict()['name']\n",
    "                #          paper_dict['plumX_'+name] = plum.mention[i]._asdict()['total']\n",
    "\n",
    "                #     for i in range(len(plum.capture)):\n",
    "                #          name = plum.capture[i]._asdict()['name']\n",
    "                #          paper_dict['plumX_'+name] = plum.capture[i]._asdict()['total']\n",
    "                # except:\n",
    "                #      pass\n",
    "                \n",
    "                with open(f'scopus_publication_files_16042024/scopus_publication_{paper_dict['eid']}.json', \"w\",encoding='utf16') as outfile: \n",
    "                    json.dump(paper_dict, outfile, ensure_ascii=False)\n",
    "                outfile.close()\n",
    "\n",
    "            #this is kind of strange, may it be that scopus returns not all authors of a publication??\n",
    "            try:\n",
    "                    del coAuthor_dict[author_dict['scopusid']]\n",
    "            except:\n",
    "                    pass\n",
    "            author_dict['coauthorCount'] = coAuthor_dict\n",
    "\n",
    "            author_dict['subjectAreaCount_detailed'] = subjectAreas_dict\n",
    "            df_subjectAreas_dict = pd.DataFrame.from_dict(subjectAreas_dict,orient='index',columns=['count'])\n",
    "            df_subjectAreas_dict = df_subjectAreas_dict.join(df_subjectAreas.loc[list(map(int, subjectAreas_dict.keys()))]['subject-classification'])\n",
    "            author_dict['subjectAreaCount_general'] = dict(zip(df_subjectAreas_dict.groupby('subject-classification').sum().index.to_list(), df_subjectAreas_dict.groupby('subject-classification').sum()['count'].to_list()))\n",
    "\n",
    "        with open(f'scopus_author_files_16042024/scopus_author_information_{author_dict['scopusID']}.json', \"w\",encoding='utf16') as outfile: \n",
    "                json.dump(author_dict, outfile, ensure_ascii=False)\n",
    "        outfile.close()\n",
    "\n",
    "\n",
    "        with open(f'saved_locations.json', \"w\") as outfile: \n",
    "            json.dump(saved_locations, outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 204/204 [08:25<00:00,  2.48s/it]\n"
     ]
    }
   ],
   "source": [
    "#openAlex publication retrieval\n",
    "with open('saved_locations.json') as fd:\n",
    "     saved_locations = json.load(fd)\n",
    "\n",
    "for i in tqdm(range(len(df_names))):\n",
    "    topics_dict = {}\n",
    "    subfields_dict = {}\n",
    "    fields_dict = {}\n",
    "\n",
    "    concepts_dict = {}\n",
    "\n",
    "    first_name = df_names['firstname'][i]\n",
    "    last_name = df_names['lastname'][i]\n",
    "    openAlexID = df_names['openAlexID'][i]\n",
    "    # openalexId = df_names['openalexID'][i]\n",
    "\n",
    "    if openAlexID != '':\n",
    "        openAlex_record = pyalex.Authors()[f\"{openAlexID}\"]\n",
    "\n",
    "        author_dict = {}\n",
    "        coAuthor_dict = {}       \n",
    "\n",
    "        author_dict['S4Sid'] = i\n",
    "        author_dict['firstname'] = df_names['firstname'][i]\n",
    "        author_dict['lastname'] = df_names['lastname'][i]\n",
    "        author_dict['scopusID'] = df_names['scopusID'][i]\n",
    "        author_dict['orcID'] = df_names['orcID'][i]\n",
    "        author_dict['openAlexID'] = df_names['openAlexID'][i]\n",
    "\n",
    "\n",
    "        #affiliation and location \n",
    "        author_dict['current_affiliation_institute'] = openAlex_record['affiliations'][0]['institution']['display_name'] if len(openAlex_record['affiliations']) > 0 else ''\n",
    "        author_dict['current_affiliation_country'] = openAlex_record['affiliations'][0]['institution']['country_code'] if len(openAlex_record['affiliations']) > 0 else ''\n",
    "\n",
    "        \n",
    "        #metrics\n",
    "        author_dict['counts_by_year'] = openAlex_record['counts_by_year']\n",
    "        author_dict['citedByCount'] = openAlex_record['cited_by_count']\n",
    "        author_dict['documentCount'] = openAlex_record['works_count']\n",
    "\n",
    "        #fetch publications of author\n",
    "        query = pyalex.Works().filter(authorships={'author.id':openAlexID}, from_publication_date='2020-01-01')\n",
    "        author_dict['publications'] = [] #if author_docs != None else ''\n",
    "\n",
    "        for item in chain(*query.paginate(per_page=200)):\n",
    "            author_dict['publications'].append(item)\n",
    "            paper_dict = {}\n",
    "            paper_dict['openAlexID'] = item['id'][21:]\n",
    "            paper_dict['doi'] = item['doi'][16:] if item['doi'] != None else ''\n",
    "            paper_dict['title'] = item['title'] if item['title'] != None else ''\n",
    "            paper_dict['type'] = item['type']   \n",
    "\n",
    "            if (item['primary_location']!=None):\n",
    "                paper_dict['landingPageURL'] = item['primary_location']['landing_page_url']\n",
    "                if (item['primary_location']['source']!=None):\n",
    "                    paper_dict['source'] = item['primary_location']['source']['display_name']\n",
    "                    paper_dict['hostOrganization'] = item['primary_location']['source']['host_organization_name']\n",
    "                else:\n",
    "                    paper_dict['source'] = ''\n",
    "                    paper_dict['hostOrganization'] = ''\n",
    "            else:\n",
    "                paper_dict['source'] = ''\n",
    "                paper_dict['landingPageURL'] = ''\n",
    "                paper_dict['hostOrganization'] = ''\n",
    "\n",
    "            paper_dict['releaseDate'] = item['publication_date']\n",
    "            paper_dict['citationCount'] = item['cited_by_count']\n",
    "            paper_dict['countsPerYear'] = item['counts_by_year']\n",
    "\n",
    "            paper_dict['authorNames'] = [author['author']['display_name'] for author in item['authorships']]\n",
    "            paper_dict['authorOpenAlexIDs'] = [author['author']['id'][21:] for author in item['authorships']]\n",
    "            paper_dict['authorCount'] = len(paper_dict['authorNames'])\n",
    "            paper_dict['numberCountries'] = item['countries_distinct_count']\n",
    "            paper_dict['numberInstitutions'] = item['institutions_distinct_count']\n",
    "\n",
    "\n",
    "            paper_dict['SDGs'] = [goal['display_name'] for goal in item['sustainable_development_goals']]\n",
    "            \n",
    "            #primary topic retrieval\n",
    "            if item['primary_topic'] != None:\n",
    "                paper_dict['primaryTopic'] = item['primary_topic']['display_name'] if item['primary_topic'] != None else ''\n",
    "                paper_dict['primaryTopicID'] = item['primary_topic']['id'][21:] if item['primary_topic'] != None else ''\n",
    "                paper_dict['primarySubfield'] = item['primary_topic']['subfield']['display_name'] if item['primary_topic'] != None else ''\n",
    "                paper_dict['primaryField'] = item['primary_topic']['field']['display_name'] if item['primary_topic'] != None else ''\n",
    "\n",
    "                #all topics\n",
    "                paper_dict['topics'] = []\n",
    "                paper_dict['topicsID'] = []\n",
    "                for topic in item['topics']:\n",
    "                    if topic['score'] > 0.5:\n",
    "                        paper_dict['topics'].append(topic['display_name'])\n",
    "                        paper_dict['topicsID'].append(topic['id'])\n",
    "                        \n",
    "                for topic in paper_dict['topics']:\n",
    "                    if topic in topics_dict:\n",
    "                        topics_dict[topic] += 1\n",
    "                    else:\n",
    "                        topics_dict[topic] = 1\n",
    "\n",
    "                #all subfields\n",
    "                paper_dict['subfields'] = []\n",
    "                for topic in item['topics']:\n",
    "                    if topic['score'] > 0.5:\n",
    "                        paper_dict['subfields'].append(topic['subfield']['display_name'])\n",
    "\n",
    "                for subfield in paper_dict['subfields']:\n",
    "                    if subfield in subfields_dict:\n",
    "                        subfields_dict[subfield] += 1\n",
    "                    else:\n",
    "                        subfields_dict[subfield] = 1\n",
    "\n",
    "                #all fields\n",
    "                paper_dict['fields'] = []\n",
    "                for topic in item['topics']:\n",
    "                    if topic['score'] > 0.5:\n",
    "                        paper_dict['fields'].append(topic['field']['display_name'])\n",
    "\n",
    "                for field in paper_dict['fields']:\n",
    "                    if field in fields_dict:\n",
    "                        fields_dict[field] += 1\n",
    "                    else:\n",
    "                        fields_dict[field] = 1\n",
    "\n",
    "            #concepts are deprected, we still gather them \n",
    "            paper_dict['concepts'] = []\n",
    "            for concept in item['concepts']:\n",
    "                if concept['score'] > 0.5:\n",
    "                    paper_dict['concepts'].append(concept['display_name'])\n",
    "\n",
    "            for concept in paper_dict['concepts']:\n",
    "                if concept in concepts_dict:\n",
    "                    concepts_dict[concept] += 1\n",
    "                else:\n",
    "                    concepts_dict[concept] = 1\n",
    "\n",
    "            #store co-Authors\n",
    "            for id in (paper_dict['authorOpenAlexIDs']):\n",
    "                if id in coAuthor_dict:\n",
    "                    coAuthor_dict[id] += 1\n",
    "                else:\n",
    "                    coAuthor_dict[id] = 1\n",
    "            \n",
    "\n",
    "            #gather reference information\n",
    "            paper_dict['references'] = [ref[21:] for ref in item['referenced_works']]\n",
    "            paper_dict['refCount'] = item['referenced_works_count']\n",
    "\n",
    "            #full reference retrieval\n",
    "            # for ref in item['referenced_works']:\n",
    "            #     ref_item = pyalex.Works()[ref[21:]]\n",
    "            #     reference_dict = {}\n",
    "            #     reference_dict['openAlexID'] = ref[21:]\n",
    "            #     reference_dict['doi'] = ref_item['doi'][16:] if ref_item['doi'] != None else ''\n",
    "            #     reference_dict['authorNames'] =  [author['author']['display_name'] for author in ref_item['authorships']]\n",
    "            #     reference_dict['authorOpenAlexIDs'] = [author['author']['id'][21:] for author in ref_item['authorships']]\n",
    "            #     reference_dict['releaseDate'] = ref_item['publication_date']\n",
    "            #     reference_dict['citationCount'] = ref_item['cited_by_count']\n",
    "            #     paper_dict['references'].append(reference_dict)\n",
    "\n",
    "            #gather related work information\n",
    "            paper_dict['relatedWorks'] = [ref[21:] for ref in item['related_works']]\n",
    "\n",
    "            #full related works retrieval\n",
    "            # for ref in item['related_works']:\n",
    "            #     ref_item = pyalex.Works()[ref[21:]]\n",
    "            #     reference_dict = {}\n",
    "            #     reference_dict['openAlexID'] = ref[21:]\n",
    "            #     reference_dict['doi'] = ref_item['doi'][16:] if ref_item['doi'] != None else ''\n",
    "            #     reference_dict['authorNames'] =  [author['author']['display_name'] for author in ref_item['authorships']]\n",
    "            #     reference_dict['authorOpenAlexIDs'] = [author['author']['id'][21:] for author in ref_item['authorships']]\n",
    "            #     reference_dict['releaseDate'] = ref_item['publication_date']\n",
    "            #     reference_dict['citationCount'] = ref_item['cited_by_count']\n",
    "            #     paper_dict['relatedWorks'].append(reference_dict)\n",
    "\n",
    "            \n",
    "            #save publication (paper_dict) as .json in specified folder\n",
    "            with open(f'openAlex_publication_files_23032024/openAlex_publication_{paper_dict['openAlexID']}.json', \"w\", encoding='utf16') as outfile: \n",
    "                json.dump(paper_dict, outfile, ensure_ascii=False)\n",
    "            outfile.close()\n",
    "\n",
    "        try:\n",
    "            del coAuthor_dict[author_dict['openAlexID']]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        author_dict['coauthorCount'] = coAuthor_dict\n",
    "\n",
    "        author_dict['topicsCount'] = topics_dict\n",
    "        author_dict['subfieldsCount'] = subfields_dict\n",
    "        author_dict['fieldsCount'] = fields_dict\n",
    "\n",
    "        author_dict['conceptsCount'] = concepts_dict\n",
    "\n",
    "        #save autthor information (paper_dict) as .json in specified folder\n",
    "        with open(f'openAlex_author_files_23032024/openAlex_author_information_{author_dict['openAlexID']}.json', \"w\", encoding='utf16') as outfile: \n",
    "                json.dump(author_dict, outfile, ensure_ascii=False)\n",
    "        outfile.close()\n",
    "\n",
    "\n",
    "        with open(f'saved_locations.json', \"w\") as outfile: \n",
    "                json.dump(saved_locations, outfile)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
