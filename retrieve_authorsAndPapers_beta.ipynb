{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from pybliometrics.scopus import AuthorRetrieval\n",
    "from pybliometrics.scopus import AbstractRetrieval\n",
    "from pybliometrics.scopus import PlumXMetrics\n",
    "\n",
    "from dicttoxml import dicttoxml\n",
    "from xml.dom.minidom import parseString\n",
    "\n",
    "#initialize geolocator to go from city, country to lat,lon\n",
    "from geopy.geocoders import Nominatim\n",
    "# Initialize Nominatim API\n",
    "geolocator = Nominatim(user_agent=\"MyApp\")\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "import pyalex\n",
    "pyalex.config.email = \"t.kagel@uu.nl\"\n",
    "\n",
    "def flatten_chain(matrix):\n",
    "     return list(chain.from_iterable(matrix))\n",
    "\n",
    "\n",
    "client_orcid = open('orcid_config.json')\n",
    "client_orcid = json.load(client_orcid)\n",
    "\n",
    "client_scopus = open('scopus_config.json')\n",
    "client_scopus = json.load(client_scopus)\n",
    "\n",
    "df_names = pd.read_csv('people_in_S4S_pureFiltered_withAuthorIDs.csv',keep_default_na=False,index_col=[0])\n",
    "# df_persons.reset_index(inplace=True)\n",
    "# df_persons.drop('Index',axis=1,inplace=True)\n",
    "# df_persons.index.names = ['Index']\n",
    "\n",
    "#orcid start up\n",
    "client_id = client_orcid['client_id']\n",
    "client_secret = client_orcid['client_secret']\n",
    "\n",
    "resp = requests.post(url=\"https://orcid.org/oauth/token\",\n",
    "                     headers={'Accept':'application/json'},\n",
    "                     data={'client_id':client_id, 'client_secret':client_secret,'grant_type': 'client_credentials', 'scope':'/read-public'}\n",
    "                     )\n",
    "access_token = resp.json()['access_token']\n",
    "\n",
    "\n",
    "df_subjectAreas = pd.read_xml('scopus_subject_classification.xml')\n",
    "df_subjectAreas.set_index('code',inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for testing purposes\n",
    "scopusId = ''\n",
    "scopus_record = AuthorRetrieval(scopusId, view='ENHANCED')\n",
    "author_docs = scopus_record.get_documents()\n",
    "# scopus_paper = author_docs[0]._asdict()\n",
    "# abstract = AbstractRetrieval(scopus_paper['eid'],view='FULL')\n",
    "\n",
    "\n",
    "# #manual GET\n",
    "# eid = scopus_paper['eid']\n",
    "resp = requests.get(url=f\"https://api.elsevier.com/author/{scopusId}/\", headers={'X-ELS-APIKey':client_scopus['apikey'], 'X-ELS-Insttoken':client_scopus['insttoken'], 'accept':'application/json'})\n",
    "# resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "scopusId = '7005917472'\n",
    "\n",
    "resp = requests.get(url=f\"https://api.elsevier.com/content/search/scopus\", headers={'X-ELS-APIKey':client_scopus['apikey'], 'X-ELS-Insttoken':client_scopus['insttoken'], 'accept':'application/json','view':'enhanced'},\n",
    "                            params={'query':f'AU-ID({scopusId}) AND PUBYEAR > 2019', 'cursor':'*'})\n",
    "print(len(resp.json()['search-results']['entry']))\n",
    "resp = requests.get(url=f\"https://api.elsevier.com/content/search/scopus\", headers={'X-ELS-APIKey':client_scopus['apikey'], 'X-ELS-Insttoken':client_scopus['insttoken'], 'accept':'application/json','view':'enhanced'},\n",
    "                            params={'query':f'AU-ID({scopusId}) AND PUBYEAR > 2019', 'start':'180'})\n",
    "print(len(resp.json()['search-results']['entry']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = requests.get(url=f\"https://api.elsevier.com/content/search/scopus\", headers={'X-ELS-APIKey':client_scopus['apikey'], 'X-ELS-Insttoken':client_scopus['insttoken'], 'accept':'application/json','view':'enhanced'},\n",
    "                            params={'query':f'AU-ID({scopusId}) AND PUBYEAR > 2019', 'cursor':'*'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = requests.get(url=f\"https://api.elsevier.com/content/search/scopus\", headers={'X-ELS-APIKey':client_scopus['apikey'], 'X-ELS-Insttoken':client_scopus['insttoken'], 'accept':'application/json','view':'enhanced'},\n",
    "                            params={'query':f'AU-ID({scopusId}) AND PUBYEAR > 2019', 'cursor':'*'})\n",
    "author_docs =  resp.json()['search-results']['entry']\n",
    "\n",
    "num_results = int(resp.json()['search-results']['opensearch:totalResults'])\n",
    "for page in np.arange(25,num_results,25):\n",
    "    resp = requests.get(url=f\"https://api.elsevier.com/content/search/scopus\", headers={'X-ELS-APIKey':client_scopus['apikey'], 'X-ELS-Insttoken':client_scopus['insttoken'], 'accept':'application/json','view':'enhanced'},\n",
    "                            params={'query':f'AU-ID({scopusId}) AND PUBYEAR > 2019', 'start':str(page)})\n",
    "    for entry in resp.json()['search-results']['entry']:\n",
    "        author_docs.append(entry)\n",
    "    # print(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scopusId = '6603780906'\n",
    "resp = requests.get(url=f\"https://api.elsevier.com/content/search/scopus\", headers={'X-ELS-APIKey':client_scopus['apikey'], 'X-ELS-Insttoken':client_scopus['insttoken'], 'accept':'application/json','view':'enhanced'},\n",
    "                            params={'query':f'AU-ID({scopusId}) AND PUBYEAR > 2019', 'cursor':'*'})\n",
    "author_docs =  resp.json()['search-results']['entry']\n",
    "url = resp.json()['search-results']['entry'][0]['prism:url']\n",
    "resp = requests.get(url=url, headers={'X-ELS-APIKey':client_scopus['apikey'], 'X-ELS-Insttoken':client_scopus['insttoken'], 'accept':'application/json','view':'enhanced'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'srctype': 'j',\n",
       " 'eid': '2-s2.0-85185346534',\n",
       " 'dc:description': 'The possibility that the Amazon forest system could soon reach a tipping point, inducing large-scale collapse, has raised global concern1–3. For 65 million years, Amazonian forests remained relatively resilient to climatic variability. Now, the region is increasingly exposed to unprecedented stress from warming temperatures, extreme droughts, deforestation and fires, even in central and remote parts of the system1. Long existing feedbacks between the forest and environmental conditions are being replaced by novel feedbacks that modify ecosystem resilience, increasing the risk of critical transition. Here we analyse existing evidence for five major drivers of water stress on Amazonian forests, as well as potential critical thresholds of those drivers that, if crossed, could trigger local, regional or even biome-wide forest collapse. By combining spatial information on various disturbances, we estimate that by 2050, 10% to 47% of Amazonian forests will be exposed to compounding disturbances that may trigger unexpected ecosystem transitions and potentially exacerbate regional climate change. Using examples of disturbed forests across the Amazon, we identify the three most plausible ecosystem trajectories, involving different feedbacks and environmental conditions. We discuss how the inherent complexity of the Amazon adds uncertainty about future dynamics, but also reveals opportunities for action. Keeping the Amazon forest resilient in the Anthropocene will depend on a combination of local efforts to end deforestation and degradation and to expand restoration, with global efforts to stop greenhouse gas emissions.',\n",
       " 'pubmed-id': '38356065',\n",
       " 'prism:coverDate': '2024-02-15',\n",
       " 'prism:aggregationType': 'Journal',\n",
       " 'prism:url': 'https://api.elsevier.com/content/abstract/scopus_id/85185346534',\n",
       " 'dc:creator': {'author': [{'ce:given-name': 'Bernardo M.',\n",
       "    'preferred-name': {'ce:given-name': 'Bernardo M.',\n",
       "     'ce:initials': 'B.M.',\n",
       "     'ce:surname': 'Flores',\n",
       "     'ce:indexed-name': 'Flores B.M.'},\n",
       "    '@seq': '1',\n",
       "    'ce:initials': 'B.M.',\n",
       "    '@_fa': 'true',\n",
       "    'affiliation': {'@id': '60017609',\n",
       "     '@href': 'https://api.elsevier.com/content/affiliation/affiliation_id/60017609'},\n",
       "    'ce:surname': 'Flores',\n",
       "    '@auid': '55624616000',\n",
       "    'author-url': 'https://api.elsevier.com/content/author/author_id/55624616000',\n",
       "    'ce:indexed-name': 'Flores B.M.'}]},\n",
       " 'link': [{'@_fa': 'true',\n",
       "   '@rel': 'self',\n",
       "   '@href': 'https://api.elsevier.com/content/abstract/scopus_id/85185346534'},\n",
       "  {'@_fa': 'true',\n",
       "   '@rel': 'scopus',\n",
       "   '@href': 'https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85185346534&origin=inward'},\n",
       "  {'@_fa': 'true',\n",
       "   '@rel': 'scopus-citedby',\n",
       "   '@href': 'https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85185346534&origin=inward'}],\n",
       " 'source-id': '21206',\n",
       " 'citedby-count': '2',\n",
       " 'prism:volume': '626',\n",
       " 'subtype': 'ar',\n",
       " 'dc:title': 'Critical transitions in the Amazon forest system',\n",
       " 'openaccess': '1',\n",
       " 'prism:issn': '14764687 00280836',\n",
       " 'publishercopyright': '© The Author(s) 2024.',\n",
       " 'prism:issueIdentifier': '7999',\n",
       " 'subtypeDescription': 'Article',\n",
       " 'prism:publicationName': 'Nature',\n",
       " 'prism:pageRange': '555-564',\n",
       " 'prism:endingPage': '564',\n",
       " 'openaccessFlag': 'true',\n",
       " 'prism:doi': '10.1038/s41586-023-06970-0',\n",
       " 'prism:startingPage': '555',\n",
       " 'dc:identifier': 'SCOPUS_ID:85185346534',\n",
       " 'dc:publisher': 'Nature Research'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.json()['abstracts-retrieval-response']['coredata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1000']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item['@code'] for item in resp.json()['abstracts-retrieval-response']['subject-areas']['subject-area']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [47:01<00:00, 13.90s/it] \n"
     ]
    }
   ],
   "source": [
    "#scopus & openAlex data retrieval\n",
    "with open('saved_locations.json') as fd:\n",
    "     saved_locations = json.load(fd)\n",
    "\n",
    "for i in tqdm(df_names.index):\n",
    "    subjectAreas_dict = {}\n",
    "\n",
    "    first_name = df_names['firstname'][i]\n",
    "    last_name = df_names['lastname'][i]\n",
    "    scopusId = df_names['scopusID'][i]\n",
    "    # openalexId = df_names['openalexID'][i]\n",
    "\n",
    "    if scopusId != '':\n",
    "\n",
    "        resp = requests.get(url=f\"https://api.elsevier.com/content/author/author_id/{scopusId}/\", headers={'X-ELS-APIKey':client_scopus['apikey'], 'X-ELS-Insttoken':client_scopus['insttoken'], 'accept':'application/json','view':'ENHANCED'})\n",
    "\n",
    "        author_dict = {}\n",
    "        coAuthor_dict = {}       \n",
    "\n",
    "        author_dict['S4Sid'] = i\n",
    "        author_dict['firstname'] = df_names['firstname'][i]\n",
    "        author_dict['lastname'] = df_names['lastname'][i]\n",
    "        author_dict['scopusID'] = df_names['scopusID'][i]\n",
    "        author_dict['orcID'] = df_names['orcID'][i]\n",
    "        # author_dict['openalexID'] = df_names['openalexID'][i]\n",
    "\n",
    "\n",
    "        #affiliation and location \n",
    "\n",
    "\n",
    "        #multiple current affiliations...\n",
    "        if isinstance(resp.json()['author-retrieval-response'][0]['author-profile']['affiliation-current']['affiliation'],list) == True:\n",
    "            author_dict['current_affiliation_institute'] = resp.json()['author-retrieval-response'][0]['author-profile']['affiliation-current']['affiliation'][0]['ip-doc']['afdispname']\n",
    "            author_dict['current_affiliation_country'] = resp.json()['author-retrieval-response'][0]['author-profile']['affiliation-current']['affiliation'][0]['ip-doc']['address']['country']\n",
    "            author_dict['current_affiliation_city'] = resp.json()['author-retrieval-response'][0]['author-profile']['affiliation-current']['affiliation'][0]['ip-doc']['address']['city']\n",
    "        else:\n",
    "            try:\n",
    "                author_dict['current_affiliation_institute'] = resp.json()['author-retrieval-response'][0]['author-profile']['affiliation-current']['affiliation']['ip-doc']['afdispname']\n",
    "                author_dict['current_affiliation_country'] = resp.json()['author-retrieval-response'][0]['author-profile']['affiliation-current']['affiliation']['ip-doc']['address']['country']\n",
    "                author_dict['current_affiliation_city'] = resp.json()['author-retrieval-response'][0]['author-profile']['affiliation-current']['affiliation']['ip-doc']['address']['city']\n",
    "            except:\n",
    "\n",
    "                author_dict['current_affiliation_institute'] = resp.json()['author-retrieval-response'][0]['author-profile']['affiliation-history']['affiliation'][0]['ip-doc']['afdispname']\n",
    "                author_dict['current_affiliation_country'] = resp.json()['author-retrieval-response'][0]['author-profile']['affiliation-history']['affiliation'][0]['ip-doc']['address']['country']\n",
    "                author_dict['current_affiliation_city'] = resp.json()['author-retrieval-response'][0]['author-profile']['affiliation-history']['affiliation'][0]['ip-doc']['address']['city']\n",
    "        \n",
    "        location_abb = f'{author_dict['current_affiliation_city']}, {author_dict['current_affiliation_country']}'\n",
    "        \n",
    "        if location_abb in saved_locations.keys():\n",
    "            location = saved_locations[location_abb]\n",
    "            author_dict['current_affiliation_lat'] = location['lat']\n",
    "            author_dict['current_affiliation_lon'] = location['lon']\n",
    "\n",
    "        else:\n",
    "            location = geolocator.geocode(query = {'country':scopus_record.affiliation_history[0]._asdict()['country'], 'city':scopus_record.affiliation_history[0]._asdict()['city']})\n",
    "\n",
    "            if location != None:\n",
    "                author_dict['current_affiliation_lat'] = location.latitude\n",
    "                author_dict['current_affiliation_lon'] = location.longitude\n",
    "                saved_locations[location_abb] = {}\n",
    "                saved_locations[location_abb]['lat'] = location.latitude\n",
    "                saved_locations[location_abb]['lon'] = location.longitude\n",
    "            else:\n",
    "                author_dict['current_affiliation_lat'] = ''\n",
    "                author_dict['current_affiliation_lon'] = ''\n",
    "                saved_locations[location_abb] = {}\n",
    "                saved_locations[location_abb]['lat'] = ''\n",
    "                saved_locations[location_abb]['lon'] = ''\n",
    "\n",
    "        author_dict['publicationRange'] = tuple([resp.json()['author-retrieval-response'][0]['author-profile']['publication-range']['@end'],resp.json()['author-retrieval-response'][0]['author-profile']['publication-range']['@start']])\n",
    "        # author_dict['researchAreas'] = [item._asdict()['area'] for item in scopus_record.subject_areas] if scopus_record.subject_areas != None else ''\n",
    "        author_dict['citationCount'] = resp.json()['author-retrieval-response'][0]['coredata']['citation-count']\n",
    "        author_dict['citedByCount'] = resp.json()['author-retrieval-response'][0]['coredata']['cited-by-count']\n",
    "        author_dict['documentCount'] = resp.json()['author-retrieval-response'][0]['coredata']['document-count']\n",
    "\n",
    "\n",
    "        resp = requests.get(url=f\"https://api.elsevier.com/content/search/scopus\", headers={'X-ELS-APIKey':client_scopus['apikey'], 'X-ELS-Insttoken':client_scopus['insttoken'], 'accept':'application/json','view':'enhanced'},\n",
    "                            params={'query':f'AU-ID({scopusId}) AND PUBYEAR > 2019', 'cursor':'*'})\n",
    "        author_docs =  resp.json()['search-results']['entry']\n",
    "\n",
    "        num_results = int(resp.json()['search-results']['opensearch:totalResults'])\n",
    "        for page in np.arange(25,num_results,25):\n",
    "            resp = requests.get(url=f\"https://api.elsevier.com/content/search/scopus\", headers={'X-ELS-APIKey':client_scopus['apikey'], 'X-ELS-Insttoken':client_scopus['insttoken'], 'accept':'application/json','view':'enhanced'},\n",
    "                                    params={'query':f'AU-ID({scopusId}) AND PUBYEAR > 2019', 'start':str(page)})\n",
    "            for entry in resp.json()['search-results']['entry']:\n",
    "                author_docs.append(entry)\n",
    "\n",
    "        author_dict['publishedArticles'] = [item['eid'] for item in author_docs] if 'error' not in resp.json()['search-results']['entry'][0].keys() else ''\n",
    "\n",
    "\n",
    "        if 'error' not in resp.json()['search-results']['entry'][0].keys():\n",
    "            for item in author_docs:\n",
    "                # scopus_paper = item._asdict()\n",
    "                paper_dict = {}\n",
    "                paper_dict['eid'] = item['eid']\n",
    "                paper_dict['doi'] = item['prism:doi'] if 'prism:doi' in item.keys() else ''\n",
    "\n",
    "                url = item['prism:url']\n",
    "                resp = requests.get(url=url, headers={'X-ELS-APIKey':client_scopus['apikey'], 'X-ELS-Insttoken':client_scopus['insttoken'], 'accept':'application/json','view':'enhanced'})\n",
    "                # if paper_dict['doi'] = ''\n",
    "\n",
    "                \n",
    "                paper_dict['title'] = resp.json()['abstracts-retrieval-response']['item']['bibrecord']['head']['citation-title']\n",
    "\n",
    "                paper_dict['authorCount'] = len(resp.json()['abstracts-retrieval-response']['authors']['author'])\n",
    "\n",
    "\n",
    "\n",
    "                date = ''\n",
    "                try:\n",
    "                    date+=resp.json()['abstracts-retrieval-response']['item']['bibrecord']['head']['source']['publicationdate']['day']\n",
    "                    date+='.'\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    date+=resp.json()['abstracts-retrieval-response']['item']['bibrecord']['head']['source']['publicationdate']['month']\n",
    "                    date+='.'\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    date+=resp.json()['abstracts-retrieval-response']['item']['bibrecord']['head']['source']['publicationdate']['year']\n",
    "                    date+='.'\n",
    "                except:\n",
    "                    pass\n",
    "                paper_dict['releaseDate'] = date \n",
    "                paper_dict['citationCount'] = resp.json()['abstracts-retrieval-response']['coredata']['citedby-count']\n",
    "                \n",
    "                paper_dict['authorNames'] = [str(author['preferred-name']['ce:given-name']) + ' ' + str(author['preferred-name']['ce:surname']) for author in resp.json()['abstracts-retrieval-response']['authors']['author']]\n",
    "                paper_dict['authorScopusIds'] =  [author['@auid'] for author in resp.json()['abstracts-retrieval-response']['authors']['author']]\n",
    "                \n",
    "                for id in (paper_dict['authorScopusIds']):\n",
    "                    if id in coAuthor_dict:\n",
    "                        coAuthor_dict[id] += 1\n",
    "                    else:\n",
    "                        coAuthor_dict[id] = 1\n",
    "                \n",
    "                try:\n",
    "                    paper_dict['type'] = resp.json()['abstracts-retrieval-response']['coredata']['subtypeDescription']\n",
    "                    # paper_dict['refCount'] = abstract.refcount if abstract.refcount != None else ''\n",
    "\n",
    "\n",
    "                    paper_dict['authorKeywords'] = [keyw['$'] for keyw in resp.json()['abstracts-retrieval-response']['authkeywords']['author-keyword']]\n",
    "                    paper_dict['idxterms'] = [keyw['$'] for keyw in resp.json()['abstracts-retrieval-response']['idxterms']['mainterm']]\n",
    "\n",
    "\n",
    "\n",
    "                    paper_dict['abstract'] = resp.json()['abstracts-retrieval-response']['coredata']['dc:description']\n",
    "\n",
    "                    paper_dict['subjectAreas'] = [item['@code'] for item in resp.json()['abstracts-retrieval-response']['subject-areas']['subject-area']]\n",
    "                    for code in paper_dict['subjectAreas']:\n",
    "                        if code in subjectAreas_dict:\n",
    "                            subjectAreas_dict[code] += 1\n",
    "                        else:\n",
    "                            subjectAreas_dict[code] = 1\n",
    "\n",
    "\n",
    "                    # paper_dict['references'] = []\n",
    "                    # for ref in (abstract.references):\n",
    "                    #     ref = ref._asdict()\n",
    "                    #     eid = \"2-s2.0-\" + ref['id']\n",
    "                    #     doi = ref['doi'] if ref['doi']!=None else \"\"\n",
    "                    #     authorNames = ref['authors'].split(\";\")if ref['authors']!= None else ''\n",
    "                    #     authorIds = ref['authors_auid'].split(\";\") if ref['authors_auid']!= None else ''\n",
    "                    #     releaseDate = ref['coverDate']\n",
    "                    #     citationCount = ref['citedbycount']\n",
    "                    #     paper_dict['references'].append({'eid':eid,\n",
    "                    #                                     'doi':doi,\n",
    "                    #                                     'authorNames':authorNames,\n",
    "                    #                                     'authorIds':authorIds,\n",
    "                    #                                     'releaseDate':releaseDate,\n",
    "                    #                                     'citationCount':citationCount})\n",
    "                except:\n",
    "                        pass\n",
    "                \n",
    "                #PLUMX metrics\n",
    "                # try:\n",
    "                #     plum = PlumXMetrics(paper_dict['doi'],id_type='doi')\n",
    "                    \n",
    "                #     for i in range(len(plum.citation)):\n",
    "                #          name = plum.citation[i]._asdict()['name']\n",
    "                #          paper_dict['plumX_'+name] = plum.citation[i]._asdict()['total']\n",
    "\n",
    "                #     for i in range(len(plum.social_media)):\n",
    "                #          name = plum.social_media[i]._asdict()['name']\n",
    "                #          paper_dict['plumX_'+name] = plum.social_media[i]._asdict()['total']\n",
    "\n",
    "                #     for i in range(len(plum.mention)):\n",
    "                #          name = plum.mention[i]._asdict()['name']\n",
    "                #          paper_dict['plumX_'+name] = plum.mention[i]._asdict()['total']\n",
    "\n",
    "                #     for i in range(len(plum.capture)):\n",
    "                #          name = plum.capture[i]._asdict()['name']\n",
    "                #          paper_dict['plumX_'+name] = plum.capture[i]._asdict()['total']\n",
    "                # except:\n",
    "                #      pass\n",
    "                \n",
    "                with open(f'scopus_publication_files_16042024/scopus_publication_{paper_dict['eid']}.json', \"w\",encoding='utf16') as outfile: \n",
    "                    json.dump(paper_dict, outfile, ensure_ascii=False)\n",
    "                outfile.close()\n",
    "\n",
    "            #this is kind of strange, may it be that scopus returns not all authors of a publication??\n",
    "            try:\n",
    "                    del coAuthor_dict[author_dict['scopusid']]\n",
    "            except:\n",
    "                    pass\n",
    "            author_dict['coauthorCount'] = coAuthor_dict\n",
    "\n",
    "            author_dict['subjectAreaCount_detailed'] = subjectAreas_dict\n",
    "            df_subjectAreas_dict = pd.DataFrame.from_dict(subjectAreas_dict,orient='index',columns=['count'])\n",
    "            df_subjectAreas_dict = df_subjectAreas_dict.join(df_subjectAreas.loc[list(map(int, subjectAreas_dict.keys()))]['subject-classification'])\n",
    "            author_dict['subjectAreaCount_general'] = dict(zip(df_subjectAreas_dict.groupby('subject-classification').sum().index.to_list(), df_subjectAreas_dict.groupby('subject-classification').sum()['count'].to_list()))\n",
    "\n",
    "        with open(f'scopus_author_files_16042024/scopus_author_information_{author_dict['scopusID']}.json', \"w\",encoding='utf16') as outfile: \n",
    "                json.dump(author_dict, outfile, ensure_ascii=False)\n",
    "        outfile.close()\n",
    "\n",
    "\n",
    "        with open(f'saved_locations.json', \"w\") as outfile: \n",
    "            json.dump(saved_locations, outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 204/204 [08:25<00:00,  2.48s/it]\n"
     ]
    }
   ],
   "source": [
    "#openAlex publication retrieval\n",
    "with open('saved_locations.json') as fd:\n",
    "     saved_locations = json.load(fd)\n",
    "\n",
    "for i in tqdm(range(len(df_names))):\n",
    "    topics_dict = {}\n",
    "    subfields_dict = {}\n",
    "    fields_dict = {}\n",
    "\n",
    "    concepts_dict = {}\n",
    "\n",
    "    first_name = df_names['firstname'][i]\n",
    "    last_name = df_names['lastname'][i]\n",
    "    openAlexID = df_names['openAlexID'][i]\n",
    "    # openalexId = df_names['openalexID'][i]\n",
    "\n",
    "    if openAlexID != '':\n",
    "        openAlex_record = pyalex.Authors()[f\"{openAlexID}\"]\n",
    "\n",
    "        author_dict = {}\n",
    "        coAuthor_dict = {}       \n",
    "\n",
    "        author_dict['S4Sid'] = i\n",
    "        author_dict['firstname'] = df_names['firstname'][i]\n",
    "        author_dict['lastname'] = df_names['lastname'][i]\n",
    "        author_dict['scopusID'] = df_names['scopusID'][i]\n",
    "        author_dict['orcID'] = df_names['orcID'][i]\n",
    "        author_dict['openAlexID'] = df_names['openAlexID'][i]\n",
    "\n",
    "\n",
    "        #affiliation and location \n",
    "        author_dict['current_affiliation_institute'] = openAlex_record['affiliations'][0]['institution']['display_name'] if len(openAlex_record['affiliations']) > 0 else ''\n",
    "        author_dict['current_affiliation_country'] = openAlex_record['affiliations'][0]['institution']['country_code'] if len(openAlex_record['affiliations']) > 0 else ''\n",
    "\n",
    "        \n",
    "        #metrics\n",
    "        author_dict['counts_by_year'] = openAlex_record['counts_by_year']\n",
    "        author_dict['citedByCount'] = openAlex_record['cited_by_count']\n",
    "        author_dict['documentCount'] = openAlex_record['works_count']\n",
    "\n",
    "        #fetch publications of author\n",
    "        query = pyalex.Works().filter(authorships={'author.id':openAlexID}, from_publication_date='2020-01-01')\n",
    "        author_dict['publications'] = [] #if author_docs != None else ''\n",
    "\n",
    "        for item in chain(*query.paginate(per_page=200)):\n",
    "            author_dict['publications'].append(item)\n",
    "            paper_dict = {}\n",
    "            paper_dict['openAlexID'] = item['id'][21:]\n",
    "            paper_dict['doi'] = item['doi'][16:] if item['doi'] != None else ''\n",
    "            paper_dict['title'] = item['title'] if item['title'] != None else ''\n",
    "            paper_dict['type'] = item['type']   \n",
    "\n",
    "            if (item['primary_location']!=None):\n",
    "                paper_dict['landingPageURL'] = item['primary_location']['landing_page_url']\n",
    "                if (item['primary_location']['source']!=None):\n",
    "                    paper_dict['source'] = item['primary_location']['source']['display_name']\n",
    "                    paper_dict['hostOrganization'] = item['primary_location']['source']['host_organization_name']\n",
    "                else:\n",
    "                    paper_dict['source'] = ''\n",
    "                    paper_dict['hostOrganization'] = ''\n",
    "            else:\n",
    "                paper_dict['source'] = ''\n",
    "                paper_dict['landingPageURL'] = ''\n",
    "                paper_dict['hostOrganization'] = ''\n",
    "\n",
    "            paper_dict['releaseDate'] = item['publication_date']\n",
    "            paper_dict['citationCount'] = item['cited_by_count']\n",
    "            paper_dict['countsPerYear'] = item['counts_by_year']\n",
    "\n",
    "            paper_dict['authorNames'] = [author['author']['display_name'] for author in item['authorships']]\n",
    "            paper_dict['authorOpenAlexIDs'] = [author['author']['id'][21:] for author in item['authorships']]\n",
    "            paper_dict['authorCount'] = len(paper_dict['authorNames'])\n",
    "            paper_dict['numberCountries'] = item['countries_distinct_count']\n",
    "            paper_dict['numberInstitutions'] = item['institutions_distinct_count']\n",
    "\n",
    "\n",
    "            paper_dict['SDGs'] = [goal['display_name'] for goal in item['sustainable_development_goals']]\n",
    "            \n",
    "            #primary topic retrieval\n",
    "            if item['primary_topic'] != None:\n",
    "                paper_dict['primaryTopic'] = item['primary_topic']['display_name'] if item['primary_topic'] != None else ''\n",
    "                paper_dict['primaryTopicID'] = item['primary_topic']['id'][21:] if item['primary_topic'] != None else ''\n",
    "                paper_dict['primarySubfield'] = item['primary_topic']['subfield']['display_name'] if item['primary_topic'] != None else ''\n",
    "                paper_dict['primaryField'] = item['primary_topic']['field']['display_name'] if item['primary_topic'] != None else ''\n",
    "\n",
    "                #all topics\n",
    "                paper_dict['topics'] = []\n",
    "                paper_dict['topicsID'] = []\n",
    "                for topic in item['topics']:\n",
    "                    if topic['score'] > 0.5:\n",
    "                        paper_dict['topics'].append(topic['display_name'])\n",
    "                        paper_dict['topicsID'].append(topic['id'])\n",
    "                        \n",
    "                for topic in paper_dict['topics']:\n",
    "                    if topic in topics_dict:\n",
    "                        topics_dict[topic] += 1\n",
    "                    else:\n",
    "                        topics_dict[topic] = 1\n",
    "\n",
    "                #all subfields\n",
    "                paper_dict['subfields'] = []\n",
    "                for topic in item['topics']:\n",
    "                    if topic['score'] > 0.5:\n",
    "                        paper_dict['subfields'].append(topic['subfield']['display_name'])\n",
    "\n",
    "                for subfield in paper_dict['subfields']:\n",
    "                    if subfield in subfields_dict:\n",
    "                        subfields_dict[subfield] += 1\n",
    "                    else:\n",
    "                        subfields_dict[subfield] = 1\n",
    "\n",
    "                #all fields\n",
    "                paper_dict['fields'] = []\n",
    "                for topic in item['topics']:\n",
    "                    if topic['score'] > 0.5:\n",
    "                        paper_dict['fields'].append(topic['field']['display_name'])\n",
    "\n",
    "                for field in paper_dict['fields']:\n",
    "                    if field in fields_dict:\n",
    "                        fields_dict[field] += 1\n",
    "                    else:\n",
    "                        fields_dict[field] = 1\n",
    "\n",
    "            #concepts are deprected, we still gather them \n",
    "            paper_dict['concepts'] = []\n",
    "            for concept in item['concepts']:\n",
    "                if concept['score'] > 0.5:\n",
    "                    paper_dict['concepts'].append(concept['display_name'])\n",
    "\n",
    "            for concept in paper_dict['concepts']:\n",
    "                if concept in concepts_dict:\n",
    "                    concepts_dict[concept] += 1\n",
    "                else:\n",
    "                    concepts_dict[concept] = 1\n",
    "\n",
    "            #store co-Authors\n",
    "            for id in (paper_dict['authorOpenAlexIDs']):\n",
    "                if id in coAuthor_dict:\n",
    "                    coAuthor_dict[id] += 1\n",
    "                else:\n",
    "                    coAuthor_dict[id] = 1\n",
    "            \n",
    "\n",
    "            #gather reference information\n",
    "            paper_dict['references'] = [ref[21:] for ref in item['referenced_works']]\n",
    "            paper_dict['refCount'] = item['referenced_works_count']\n",
    "\n",
    "            #full reference retrieval\n",
    "            # for ref in item['referenced_works']:\n",
    "            #     ref_item = pyalex.Works()[ref[21:]]\n",
    "            #     reference_dict = {}\n",
    "            #     reference_dict['openAlexID'] = ref[21:]\n",
    "            #     reference_dict['doi'] = ref_item['doi'][16:] if ref_item['doi'] != None else ''\n",
    "            #     reference_dict['authorNames'] =  [author['author']['display_name'] for author in ref_item['authorships']]\n",
    "            #     reference_dict['authorOpenAlexIDs'] = [author['author']['id'][21:] for author in ref_item['authorships']]\n",
    "            #     reference_dict['releaseDate'] = ref_item['publication_date']\n",
    "            #     reference_dict['citationCount'] = ref_item['cited_by_count']\n",
    "            #     paper_dict['references'].append(reference_dict)\n",
    "\n",
    "            #gather related work information\n",
    "            paper_dict['relatedWorks'] = [ref[21:] for ref in item['related_works']]\n",
    "\n",
    "            #full related works retrieval\n",
    "            # for ref in item['related_works']:\n",
    "            #     ref_item = pyalex.Works()[ref[21:]]\n",
    "            #     reference_dict = {}\n",
    "            #     reference_dict['openAlexID'] = ref[21:]\n",
    "            #     reference_dict['doi'] = ref_item['doi'][16:] if ref_item['doi'] != None else ''\n",
    "            #     reference_dict['authorNames'] =  [author['author']['display_name'] for author in ref_item['authorships']]\n",
    "            #     reference_dict['authorOpenAlexIDs'] = [author['author']['id'][21:] for author in ref_item['authorships']]\n",
    "            #     reference_dict['releaseDate'] = ref_item['publication_date']\n",
    "            #     reference_dict['citationCount'] = ref_item['cited_by_count']\n",
    "            #     paper_dict['relatedWorks'].append(reference_dict)\n",
    "\n",
    "            \n",
    "            #save publication (paper_dict) as .json in specified folder\n",
    "            with open(f'openAlex_publication_files_23032024/openAlex_publication_{paper_dict['openAlexID']}.json', \"w\", encoding='utf16') as outfile: \n",
    "                json.dump(paper_dict, outfile, ensure_ascii=False)\n",
    "            outfile.close()\n",
    "\n",
    "        try:\n",
    "            del coAuthor_dict[author_dict['openAlexID']]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        author_dict['coauthorCount'] = coAuthor_dict\n",
    "\n",
    "        author_dict['topicsCount'] = topics_dict\n",
    "        author_dict['subfieldsCount'] = subfields_dict\n",
    "        author_dict['fieldsCount'] = fields_dict\n",
    "\n",
    "        author_dict['conceptsCount'] = concepts_dict\n",
    "\n",
    "        #save autthor information (paper_dict) as .json in specified folder\n",
    "        with open(f'openAlex_author_files_23032024/openAlex_author_information_{author_dict['openAlexID']}.json', \"w\", encoding='utf16') as outfile: \n",
    "                json.dump(author_dict, outfile, ensure_ascii=False)\n",
    "        outfile.close()\n",
    "\n",
    "\n",
    "        with open(f'saved_locations.json', \"w\") as outfile: \n",
    "                json.dump(saved_locations, outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'https://openalex.org/W4307549427',\n",
       " 'doi': 'https://doi.org/10.3390/w14213397',\n",
       " 'title': 'Assessment of a Multi-Layer Aquifer Vulnerability Using a Multi-Parameter Decision-Making Method in Mosha Plain, Iran',\n",
       " 'display_name': 'Assessment of a Multi-Layer Aquifer Vulnerability Using a Multi-Parameter Decision-Making Method in Mosha Plain, Iran',\n",
       " 'publication_year': 2022,\n",
       " 'publication_date': '2022-10-26',\n",
       " 'ids': {'openalex': 'https://openalex.org/W4307549427',\n",
       "  'doi': 'https://doi.org/10.3390/w14213397'},\n",
       " 'language': 'en',\n",
       " 'primary_location': {'is_oa': True,\n",
       "  'landing_page_url': 'https://doi.org/10.3390/w14213397',\n",
       "  'pdf_url': 'https://www.mdpi.com/2073-4441/14/21/3397/pdf?version=1667817452',\n",
       "  'source': {'id': 'https://openalex.org/S134216166',\n",
       "   'display_name': 'Water',\n",
       "   'issn_l': '2073-4441',\n",
       "   'issn': ['2073-4441'],\n",
       "   'is_oa': True,\n",
       "   'is_in_doaj': True,\n",
       "   'host_organization': 'https://openalex.org/P4310310987',\n",
       "   'host_organization_name': 'Multidisciplinary Digital Publishing Institute',\n",
       "   'host_organization_lineage': ['https://openalex.org/P4310310987'],\n",
       "   'host_organization_lineage_names': ['Multidisciplinary Digital Publishing Institute'],\n",
       "   'type': 'journal'},\n",
       "  'license': 'cc-by',\n",
       "  'version': 'publishedVersion',\n",
       "  'is_accepted': True,\n",
       "  'is_published': True},\n",
       " 'type': 'article',\n",
       " 'type_crossref': 'journal-article',\n",
       " 'indexed_in': ['crossref', 'doaj'],\n",
       " 'open_access': {'is_oa': True,\n",
       "  'oa_status': 'gold',\n",
       "  'oa_url': 'https://www.mdpi.com/2073-4441/14/21/3397/pdf?version=1667817452',\n",
       "  'any_repository_has_fulltext': True},\n",
       " 'authorships': [{'author_position': 'first',\n",
       "   'author': {'id': 'https://openalex.org/A5005689547',\n",
       "    'display_name': 'Yaser Nikpeyman',\n",
       "    'orcid': 'https://orcid.org/0000-0002-4708-5588'},\n",
       "   'institutions': [{'id': 'https://openalex.org/I48379061',\n",
       "     'display_name': 'Shahid Beheshti University',\n",
       "     'ror': 'https://ror.org/0091vmj44',\n",
       "     'country_code': 'IR',\n",
       "     'type': 'education',\n",
       "     'lineage': ['https://openalex.org/I48379061']}],\n",
       "   'countries': ['IR'],\n",
       "   'is_corresponding': False,\n",
       "   'raw_author_name': 'Yaser Nikpeyman',\n",
       "   'raw_affiliation_string': 'Department of Minerals and Groundwater Resources, Faculty of Earth Sciences, Shahid Beheshti University, Tehran 198396941, Iran',\n",
       "   'raw_affiliation_strings': ['Department of Minerals and Groundwater Resources, Faculty of Earth Sciences, Shahid Beheshti University, Tehran 198396941, Iran']},\n",
       "  {'author_position': 'middle',\n",
       "   'author': {'id': 'https://openalex.org/A5005920635',\n",
       "    'display_name': 'Vahid Nikpeyman',\n",
       "    'orcid': None},\n",
       "   'institutions': [{'id': 'https://openalex.org/I193662353',\n",
       "     'display_name': 'Utrecht University',\n",
       "     'ror': 'https://ror.org/04pp8hn57',\n",
       "     'country_code': 'NL',\n",
       "     'type': 'education',\n",
       "     'lineage': ['https://openalex.org/I193662353']}],\n",
       "   'countries': ['NL'],\n",
       "   'is_corresponding': False,\n",
       "   'raw_author_name': 'Vahid Nikpeyman',\n",
       "   'raw_affiliation_string': 'Department of Earth Sciences, Utrecht University, 3584 CB Utrecht, The Netherlands',\n",
       "   'raw_affiliation_strings': ['Department of Earth Sciences, Utrecht University, 3584 CB Utrecht, The Netherlands']},\n",
       "  {'author_position': 'middle',\n",
       "   'author': {'id': 'https://openalex.org/A5067923262',\n",
       "    'display_name': 'Reza Derakhshani',\n",
       "    'orcid': 'https://orcid.org/0000-0001-7499-4384'},\n",
       "   'institutions': [{'id': 'https://openalex.org/I193662353',\n",
       "     'display_name': 'Utrecht University',\n",
       "     'ror': 'https://ror.org/04pp8hn57',\n",
       "     'country_code': 'NL',\n",
       "     'type': 'education',\n",
       "     'lineage': ['https://openalex.org/I193662353']},\n",
       "    {'id': 'https://openalex.org/I115566878',\n",
       "     'display_name': 'Shahid Bahonar University of Kerman',\n",
       "     'ror': 'https://ror.org/04zn42r77',\n",
       "     'country_code': 'IR',\n",
       "     'type': 'education',\n",
       "     'lineage': ['https://openalex.org/I115566878']}],\n",
       "   'countries': ['IR', 'NL'],\n",
       "   'is_corresponding': True,\n",
       "   'raw_author_name': 'Reza Derakhshani',\n",
       "   'raw_affiliation_string': 'Department of Earth Sciences, Utrecht University, 3584 CB Utrecht, The Netherlands; Department of Geology, Shahid Bahonar University, Kerman 7619613439, Iran',\n",
       "   'raw_affiliation_strings': ['Department of Earth Sciences, Utrecht University, 3584 CB Utrecht, The Netherlands',\n",
       "    'Department of Geology, Shahid Bahonar University, Kerman 7619613439, Iran']},\n",
       "  {'author_position': 'last',\n",
       "   'author': {'id': 'https://openalex.org/A5027539737',\n",
       "    'display_name': 'Amir Raoof',\n",
       "    'orcid': 'https://orcid.org/0000-0003-1613-6546'},\n",
       "   'institutions': [{'id': 'https://openalex.org/I193662353',\n",
       "     'display_name': 'Utrecht University',\n",
       "     'ror': 'https://ror.org/04pp8hn57',\n",
       "     'country_code': 'NL',\n",
       "     'type': 'education',\n",
       "     'lineage': ['https://openalex.org/I193662353']}],\n",
       "   'countries': ['NL'],\n",
       "   'is_corresponding': False,\n",
       "   'raw_author_name': 'Amir Raoof',\n",
       "   'raw_affiliation_string': 'Department of Earth Sciences, Utrecht University, 3584 CB Utrecht, The Netherlands',\n",
       "   'raw_affiliation_strings': ['Department of Earth Sciences, Utrecht University, 3584 CB Utrecht, The Netherlands']}],\n",
       " 'countries_distinct_count': 2,\n",
       " 'institutions_distinct_count': 3,\n",
       " 'corresponding_author_ids': ['https://openalex.org/A5067923262'],\n",
       " 'corresponding_institution_ids': ['https://openalex.org/I193662353',\n",
       "  'https://openalex.org/I115566878'],\n",
       " 'apc_list': None,\n",
       " 'apc_paid': None,\n",
       " 'has_fulltext': True,\n",
       " 'fulltext_origin': 'pdf',\n",
       " 'cited_by_count': 1,\n",
       " 'cited_by_percentile_year': {'min': 68, 'max': 78},\n",
       " 'biblio': {'volume': '14',\n",
       "  'issue': '21',\n",
       "  'first_page': '3397',\n",
       "  'last_page': '3397'},\n",
       " 'is_retracted': False,\n",
       " 'is_paratext': False,\n",
       " 'primary_topic': {'id': 'https://openalex.org/T10398',\n",
       "  'display_name': 'Stable Isotope Analysis of Groundwater and Precipitation',\n",
       "  'score': 0.9989,\n",
       "  'subfield': {'id': 'https://openalex.org/subfields/1906',\n",
       "   'display_name': 'Geochemistry and Petrology'},\n",
       "  'field': {'id': 'https://openalex.org/fields/19',\n",
       "   'display_name': 'Earth and Planetary Sciences'},\n",
       "  'domain': {'id': 'https://openalex.org/domains/3',\n",
       "   'display_name': 'Physical Sciences'}},\n",
       " 'topics': [{'id': 'https://openalex.org/T10398',\n",
       "   'display_name': 'Stable Isotope Analysis of Groundwater and Precipitation',\n",
       "   'score': 0.9989,\n",
       "   'subfield': {'id': 'https://openalex.org/subfields/1906',\n",
       "    'display_name': 'Geochemistry and Petrology'},\n",
       "   'field': {'id': 'https://openalex.org/fields/19',\n",
       "    'display_name': 'Earth and Planetary Sciences'},\n",
       "   'domain': {'id': 'https://openalex.org/domains/3',\n",
       "    'display_name': 'Physical Sciences'}},\n",
       "  {'id': 'https://openalex.org/T12543',\n",
       "   'display_name': 'Mapping Groundwater Potential Zones Using GIS Techniques',\n",
       "   'score': 0.9984,\n",
       "   'subfield': {'id': 'https://openalex.org/subfields/2305',\n",
       "    'display_name': 'Environmental Engineering'},\n",
       "   'field': {'id': 'https://openalex.org/fields/23',\n",
       "    'display_name': 'Environmental Science'},\n",
       "   'domain': {'id': 'https://openalex.org/domains/3',\n",
       "    'display_name': 'Physical Sciences'}},\n",
       "  {'id': 'https://openalex.org/T10894',\n",
       "   'display_name': 'Groundwater Flow and Transport Modeling',\n",
       "   'score': 0.9938,\n",
       "   'subfield': {'id': 'https://openalex.org/subfields/2305',\n",
       "    'display_name': 'Environmental Engineering'},\n",
       "   'field': {'id': 'https://openalex.org/fields/23',\n",
       "    'display_name': 'Environmental Science'},\n",
       "   'domain': {'id': 'https://openalex.org/domains/3',\n",
       "    'display_name': 'Physical Sciences'}}],\n",
       " 'keywords': [{'keyword': 'vulnerability', 'score': 0.3457},\n",
       "  {'keyword': 'mosha plain', 'score': 0.3209},\n",
       "  {'keyword': 'multi-layer', 'score': 0.25},\n",
       "  {'keyword': 'multi-parameter', 'score': 0.25},\n",
       "  {'keyword': 'decision-making', 'score': 0.25}],\n",
       " 'concepts': [{'id': 'https://openalex.org/C75622301',\n",
       "   'wikidata': 'https://www.wikidata.org/wiki/Q208791',\n",
       "   'display_name': 'Aquifer',\n",
       "   'level': 3,\n",
       "   'score': 0.92558527},\n",
       "  {'id': 'https://openalex.org/C76177295',\n",
       "   'wikidata': 'https://www.wikidata.org/wiki/Q161598',\n",
       "   'display_name': 'Groundwater',\n",
       "   'level': 2,\n",
       "   'score': 0.7436396},\n",
       "  {'id': 'https://openalex.org/C76886044',\n",
       "   'wikidata': 'https://www.wikidata.org/wiki/Q2883300',\n",
       "   'display_name': 'Hydrology (agriculture)',\n",
       "   'level': 2,\n",
       "   'score': 0.53574294},\n",
       "  {'id': 'https://openalex.org/C39432304',\n",
       "   'wikidata': 'https://www.wikidata.org/wiki/Q188847',\n",
       "   'display_name': 'Environmental science',\n",
       "   'level': 0,\n",
       "   'score': 0.5221446},\n",
       "  {'id': 'https://openalex.org/C95713431',\n",
       "   'wikidata': 'https://www.wikidata.org/wiki/Q631425',\n",
       "   'display_name': 'Vulnerability (computing)',\n",
       "   'level': 2,\n",
       "   'score': 0.50597495},\n",
       "  {'id': 'https://openalex.org/C524765639',\n",
       "   'wikidata': 'https://www.wikidata.org/wiki/Q1501619',\n",
       "   'display_name': 'Water resource management',\n",
       "   'level': 1,\n",
       "   'score': 0.4950325},\n",
       "  {'id': 'https://openalex.org/C127313418',\n",
       "   'wikidata': 'https://www.wikidata.org/wiki/Q1069',\n",
       "   'display_name': 'Geology',\n",
       "   'level': 0,\n",
       "   'score': 0.4088483},\n",
       "  {'id': 'https://openalex.org/C187320778',\n",
       "   'wikidata': 'https://www.wikidata.org/wiki/Q1349130',\n",
       "   'display_name': 'Geotechnical engineering',\n",
       "   'level': 1,\n",
       "   'score': 0.09250459},\n",
       "  {'id': 'https://openalex.org/C38652104',\n",
       "   'wikidata': 'https://www.wikidata.org/wiki/Q3510521',\n",
       "   'display_name': 'Computer security',\n",
       "   'level': 1,\n",
       "   'score': 0.0},\n",
       "  {'id': 'https://openalex.org/C41008148',\n",
       "   'wikidata': 'https://www.wikidata.org/wiki/Q21198',\n",
       "   'display_name': 'Computer science',\n",
       "   'level': 0,\n",
       "   'score': 0.0}],\n",
       " 'mesh': [],\n",
       " 'locations_count': 3,\n",
       " 'locations': [{'is_oa': True,\n",
       "   'landing_page_url': 'https://doi.org/10.3390/w14213397',\n",
       "   'pdf_url': 'https://www.mdpi.com/2073-4441/14/21/3397/pdf?version=1667817452',\n",
       "   'source': {'id': 'https://openalex.org/S134216166',\n",
       "    'display_name': 'Water',\n",
       "    'issn_l': '2073-4441',\n",
       "    'issn': ['2073-4441'],\n",
       "    'is_oa': True,\n",
       "    'is_in_doaj': True,\n",
       "    'host_organization': 'https://openalex.org/P4310310987',\n",
       "    'host_organization_name': 'Multidisciplinary Digital Publishing Institute',\n",
       "    'host_organization_lineage': ['https://openalex.org/P4310310987'],\n",
       "    'host_organization_lineage_names': ['Multidisciplinary Digital Publishing Institute'],\n",
       "    'type': 'journal'},\n",
       "   'license': 'cc-by',\n",
       "   'version': 'publishedVersion',\n",
       "   'is_accepted': True,\n",
       "   'is_published': True},\n",
       "  {'is_oa': False,\n",
       "   'landing_page_url': 'https://doaj.org/article/f0ba0675c2164e0f8fd4bc1b3697996b',\n",
       "   'pdf_url': None,\n",
       "   'source': {'id': 'https://openalex.org/S4306401280',\n",
       "    'display_name': 'DOAJ (DOAJ: Directory of Open Access Journals)',\n",
       "    'issn_l': None,\n",
       "    'issn': None,\n",
       "    'is_oa': True,\n",
       "    'is_in_doaj': False,\n",
       "    'host_organization': None,\n",
       "    'host_organization_name': None,\n",
       "    'host_organization_lineage': [],\n",
       "    'host_organization_lineage_names': [],\n",
       "    'type': 'repository'},\n",
       "   'license': None,\n",
       "   'version': None,\n",
       "   'is_accepted': False,\n",
       "   'is_published': False},\n",
       "  {'is_oa': True,\n",
       "   'landing_page_url': 'https://dspace.library.uu.nl/handle/1874/423554',\n",
       "   'pdf_url': 'https://dspace.library.uu.nl/bitstream/handle/1874/423554/water_14_03397.pdf?sequence=1&isAllowed=y',\n",
       "   'source': {'id': 'https://openalex.org/S4306401843',\n",
       "    'display_name': 'Data Archiving and Networked Services (DANS)',\n",
       "    'issn_l': None,\n",
       "    'issn': None,\n",
       "    'is_oa': True,\n",
       "    'is_in_doaj': False,\n",
       "    'host_organization': 'https://openalex.org/I1322597698',\n",
       "    'host_organization_name': 'Royal Netherlands Academy of Arts and Sciences',\n",
       "    'host_organization_lineage': ['https://openalex.org/I1322597698'],\n",
       "    'host_organization_lineage_names': ['Royal Netherlands Academy of Arts and Sciences'],\n",
       "    'type': 'repository'},\n",
       "   'license': 'cc-by',\n",
       "   'version': 'publishedVersion',\n",
       "   'is_accepted': True,\n",
       "   'is_published': True}],\n",
       " 'best_oa_location': {'is_oa': True,\n",
       "  'landing_page_url': 'https://doi.org/10.3390/w14213397',\n",
       "  'pdf_url': 'https://www.mdpi.com/2073-4441/14/21/3397/pdf?version=1667817452',\n",
       "  'source': {'id': 'https://openalex.org/S134216166',\n",
       "   'display_name': 'Water',\n",
       "   'issn_l': '2073-4441',\n",
       "   'issn': ['2073-4441'],\n",
       "   'is_oa': True,\n",
       "   'is_in_doaj': True,\n",
       "   'host_organization': 'https://openalex.org/P4310310987',\n",
       "   'host_organization_name': 'Multidisciplinary Digital Publishing Institute',\n",
       "   'host_organization_lineage': ['https://openalex.org/P4310310987'],\n",
       "   'host_organization_lineage_names': ['Multidisciplinary Digital Publishing Institute'],\n",
       "   'type': 'journal'},\n",
       "  'license': 'cc-by',\n",
       "  'version': 'publishedVersion',\n",
       "  'is_accepted': True,\n",
       "  'is_published': True},\n",
       " 'sustainable_development_goals': [{'id': 'https://metadata.un.org/sdg/11',\n",
       "   'display_name': 'Sustainable cities and communities',\n",
       "   'score': 0.62}],\n",
       " 'grants': [],\n",
       " 'referenced_works_count': 35,\n",
       " 'referenced_works': ['https://openalex.org/W775189321',\n",
       "  'https://openalex.org/W985482098',\n",
       "  'https://openalex.org/W1964242070',\n",
       "  'https://openalex.org/W1965920041',\n",
       "  'https://openalex.org/W1969920687',\n",
       "  'https://openalex.org/W1984108903',\n",
       "  'https://openalex.org/W1984530120',\n",
       "  'https://openalex.org/W1992833559',\n",
       "  'https://openalex.org/W1997159081',\n",
       "  'https://openalex.org/W2003970014',\n",
       "  'https://openalex.org/W2005253492',\n",
       "  'https://openalex.org/W2011811799',\n",
       "  'https://openalex.org/W2013990421',\n",
       "  'https://openalex.org/W2022286776',\n",
       "  'https://openalex.org/W2039390536',\n",
       "  'https://openalex.org/W2045986706',\n",
       "  'https://openalex.org/W2053121072',\n",
       "  'https://openalex.org/W2053682001',\n",
       "  'https://openalex.org/W2079108930',\n",
       "  'https://openalex.org/W2084773003',\n",
       "  'https://openalex.org/W2089347286',\n",
       "  'https://openalex.org/W2110696967',\n",
       "  'https://openalex.org/W2161692005',\n",
       "  'https://openalex.org/W2165335913',\n",
       "  'https://openalex.org/W2170585319',\n",
       "  'https://openalex.org/W2273149604',\n",
       "  'https://openalex.org/W2330607635',\n",
       "  'https://openalex.org/W2335023010',\n",
       "  'https://openalex.org/W2354469854',\n",
       "  'https://openalex.org/W2400340553',\n",
       "  'https://openalex.org/W2491927449',\n",
       "  'https://openalex.org/W2509435117',\n",
       "  'https://openalex.org/W2531068875',\n",
       "  'https://openalex.org/W2778251009',\n",
       "  'https://openalex.org/W4229038361'],\n",
       " 'related_works': ['https://openalex.org/W2387473253',\n",
       "  'https://openalex.org/W985732587',\n",
       "  'https://openalex.org/W2350422742',\n",
       "  'https://openalex.org/W1947007732',\n",
       "  'https://openalex.org/W2922239277',\n",
       "  'https://openalex.org/W3036980091',\n",
       "  'https://openalex.org/W1608852890',\n",
       "  'https://openalex.org/W2007103879',\n",
       "  'https://openalex.org/W2034460869',\n",
       "  'https://openalex.org/W1969385569'],\n",
       " 'ngrams_url': 'https://api.openalex.org/works/W4307549427/ngrams',\n",
       " 'abstract_inverted_index': {'In': [0],\n",
       "  'recent': [1],\n",
       "  'decades,': [2],\n",
       "  'there': [3],\n",
       "  'has': [4, 27],\n",
       "  'been': [5],\n",
       "  'a': [6, 29, 50, 69],\n",
       "  'growing': [7],\n",
       "  'emphasis': [8],\n",
       "  'on': [9],\n",
       "  'assessing': [10],\n",
       "  'aquifer': [11, 90, 145, 158, 180],\n",
       "  'vulnerability.': [12],\n",
       "  'Given': [13],\n",
       "  'the': [14,\n",
       "   20,\n",
       "   24,\n",
       "   41,\n",
       "   53,\n",
       "   63,\n",
       "   83,\n",
       "   89,\n",
       "   92,\n",
       "   113,\n",
       "   135,\n",
       "   144,\n",
       "   150,\n",
       "   157,\n",
       "   172,\n",
       "   179,\n",
       "   183],\n",
       "  'availability': [15],\n",
       "  'of': [16, 52, 76],\n",
       "  'spatial': [17],\n",
       "  'data': [18, 67, 71],\n",
       "  'and': [19, 34, 44, 73, 108, 124, 127, 164, 181],\n",
       "  'GIS': [21, 42],\n",
       "  'advantages,': [22],\n",
       "  'mapping': [23],\n",
       "  'groundwater': [25, 36, 60, 80, 185],\n",
       "  'vulnerability': [26, 61],\n",
       "  'become': [28],\n",
       "  'common': [30],\n",
       "  'tool': [31],\n",
       "  'for': [32],\n",
       "  'protecting': [33],\n",
       "  'managing': [35],\n",
       "  'resources.': [37, 186],\n",
       "  'Here,': [38],\n",
       "  'we': [39],\n",
       "  'applied': [40],\n",
       "  'indexing': [43],\n",
       "  'an': [45],\n",
       "  'overlay': [46],\n",
       "  'method': [47],\n",
       "  'to': [48, 58, 82, 149],\n",
       "  'explore': [49],\n",
       "  'combination': [51],\n",
       "  'potential': [54, 93],\n",
       "  'contamination': [55],\n",
       "  'factors': [56],\n",
       "  'needed': [57],\n",
       "  'assess': [59, 88],\n",
       "  'in': [62],\n",
       "  'Mosha': [64],\n",
       "  'aquifer.': [65],\n",
       "  'The': [66],\n",
       "  'from': [68, 159],\n",
       "  'borehole': [70],\n",
       "  'logger': [72],\n",
       "  'chemical': [74],\n",
       "  'analysis': [75],\n",
       "  'spring': [77],\n",
       "  'water': [78, 122],\n",
       "  'show': [79],\n",
       "  'responses': [81],\n",
       "  'surface': [84],\n",
       "  'contaminating': [85, 94],\n",
       "  'sources.': [86],\n",
       "  'To': [87],\n",
       "  'vulnerability,': [91],\n",
       "  'sources': [95],\n",
       "  'were': [96, 138],\n",
       "  'classified': [97],\n",
       "  'into': [98, 156, 171, 178],\n",
       "  'three': [99],\n",
       "  'groups,': [100],\n",
       "  'namely': [101],\n",
       "  '(1)': [102],\n",
       "  'geological': [103],\n",
       "  'characteristics': [104],\n",
       "  'such': [105, 119],\n",
       "  'as': [106, 120],\n",
       "  'lithology': [107],\n",
       "  'structural': [109],\n",
       "  'geology': [110],\n",
       "  'features;': [111],\n",
       "  '(2)': [112],\n",
       "  'infrastructures': [114],\n",
       "  'induced': [115],\n",
       "  'by': [116],\n",
       "  'human': [117],\n",
       "  'activities': [118],\n",
       "  'roads,': [121],\n",
       "  'wells,': [123],\n",
       "  'pit': [125, 165],\n",
       "  'latrines;': [126],\n",
       "  '(3)': [128],\n",
       "  'land': [129],\n",
       "  'use.': [130],\n",
       "  'By': [131],\n",
       "  'considering': [132],\n",
       "  'these': [133],\n",
       "  'components,': [134],\n",
       "  'risk': [136],\n",
       "  'maps': [137],\n",
       "  'produced.': [139],\n",
       "  'Our': [140],\n",
       "  'findings': [141],\n",
       "  'indicate': [142],\n",
       "  'that': [143, 153, 174],\n",
       "  'is': [146],\n",
       "  'very': [147],\n",
       "  'responsive': [148],\n",
       "  'anthropogenic': [151],\n",
       "  'contaminants': [152],\n",
       "  'may': [154, 175],\n",
       "  'leak': [155, 177],\n",
       "  'urbanized': [160],\n",
       "  'areas.': [161],\n",
       "  'Additionally,': [162],\n",
       "  'roads': [163],\n",
       "  'latrines': [166],\n",
       "  'can': [167],\n",
       "  'significantly': [168],\n",
       "  'release': [169],\n",
       "  'pollutants': [170],\n",
       "  'environment': [173],\n",
       "  'eventually': [176],\n",
       "  'contaminate': [182],\n",
       "  'underlying': [184]},\n",
       " 'cited_by_api_url': 'https://api.openalex.org/works?filter=cites:W4307549427',\n",
       " 'counts_by_year': [{'year': 2023, 'cited_by_count': 1}],\n",
       " 'updated_date': '2024-03-25T11:01:30.395407',\n",
       " 'created_date': '2022-11-03'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected 'else' after 'if' expression (2464808128.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[16], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    paper_dict['source'] = item['primary_location']['source']['display_name'] if (item['primary_location']!=None) if (item['primary_location']['source']!=None) else ''\u001b[0m\n\u001b[1;37m                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expected 'else' after 'if' expression\n"
     ]
    }
   ],
   "source": [
    "paper_dict['source'] = item['primary_location']['source']['display_name'] if (item['primary_location']!=None) if (item['primary_location']['source']!=None) else ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_dict['source']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
